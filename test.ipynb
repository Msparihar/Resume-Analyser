{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF to TextDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "reader = PdfReader(\"resume.pdf\")\n",
    "number_of_pages = len(reader.pages)\n",
    "number_of_pages\n",
    "\n",
    "with open('document.txt', 'w',encoding='utf-8') as text_file:\n",
    "    for page in range(number_of_pages):\n",
    "        text = reader.pages[page].extract_text()\n",
    "        text_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resume is 36.51% match for the Job\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# load the English NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# read the resume text from a file\n",
    "with open(\"document.txt\", \"r\",encoding=\"utf-8\") as f:\n",
    "    resume_text = f.read()\n",
    "\n",
    "# use the NER model to extract skills from the resume text\n",
    "doc = nlp(resume_text)\n",
    "skills = []\n",
    "for ent in doc.ents:\n",
    "    skills.append(ent.text)\n",
    "\n",
    "required_skills = [\n",
    "    \"Java\",\n",
    "    \"C++\",\n",
    "    \"Python\",\n",
    "    \"C#\",\n",
    "    \"PHP\",\n",
    "    \"JavaScript\",\n",
    "    \"HTML\",\n",
    "    \"CSS\",\n",
    "    \"SQL\",\n",
    "    \"Agile\",\n",
    "    \"Scrum\",\n",
    "    \"Git\",\n",
    "    \"Linux\",\n",
    "    \"Docker\",\n",
    "    \"Kubernetes\",\n",
    "    \"CI/CD\",\n",
    "]\n",
    "skills = [skill for skill in skills if skill in required_skills]\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Create a CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the two sets of skills\n",
    "vectorizer.fit_transform(skills + required_skills)\n",
    "\n",
    "# Convert each set of skills to a vector of word counts\n",
    "technical_skills_vector = vectorizer.transform([', '.join(skills)])\n",
    "skills_vector = vectorizer.transform([', '.join(required_skills)])\n",
    "\n",
    "# Calculate the cosine similarity between the two vectors\n",
    "cosine_sim = cosine_similarity(technical_skills_vector, skills_vector)[0][0]\n",
    "\n",
    "# Convert the cosine similarity to a percentage\n",
    "similarity_percent = cosine_sim * 100\n",
    "\n",
    "print(\"The resume is {:.2f}% match for the Job\".format(similarity_percent))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a9100d15347cee4db40e802c1e505938e6b867b373c1758aecb013e2409a160"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
